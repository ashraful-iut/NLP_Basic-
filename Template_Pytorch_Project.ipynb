{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashraful-iut/NLP_Basic-/blob/main/Template_Pytorch_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "U9PQecnWhs1w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import random\n",
        "from math import ceil\n",
        "from time import time\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import models\n",
        "\n",
        "#from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet50\n",
        "softmax = nn.Softmax(dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6pC1BaBQiktF"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY6rTMJgi7ev",
        "outputId": "eed7445d-3bb2-463f-e974-b76f5dfc816d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 3430M  100 3430M    0     0   159M      0  0:00:21  0:00:21 --:--:--  177M\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o 'HatefulMemes.zip' 'https://drive.google.com/u/0/uc?id=1e--1ysAumCP6AtWpDvEFULLRLVMxCu5m&export=download&confirm=t'\n",
        "shutil.unpack_archive(\"/content/HatefulMemes.zip\", \"/content/HatefulMemes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-jVnQWdjp87"
      },
      "outputs": [],
      "source": [
        "lines = []\n",
        "import json\n",
        "with open('/content/HatefulMemes/archive/data/train.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        line_val = json.loads(line)\n",
        "        lines.append(line_val)\n",
        "train_df = pd.DataFrame()\n",
        "file_paths = []\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for line in lines:\n",
        "    file_paths.append(\"/content/HatefulMemes/archive/data/\" + dict(line)[\"img\"])\n",
        "    labels.append(str(dict(line)[\"label\"]))\n",
        "    texts.append(str(dict(line)[\"text\"]))\n",
        "\n",
        "train_df[\"filepath\"] = file_paths\n",
        "train_df[\"label\"] = labels\n",
        "train_df[\"text\"] = texts\n",
        "\n",
        "lines = []\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/content/HatefulMemes/archive/data/dev.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        line_val = json.loads(line)\n",
        "        lines.append(line_val)\n",
        "\n",
        "valid_df = pd.DataFrame()\n",
        "file_paths = []\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for line in lines:\n",
        "    file_paths.append(\"/content/HatefulMemes/archive/data/\" + dict(line)[\"img\"])\n",
        "    labels.append(str(dict(line)[\"label\"]))\n",
        "    texts.append(str(dict(line)[\"text\"]))\n",
        "\n",
        "valid_df[\"filepath\"] = file_paths\n",
        "valid_df[\"label\"] = labels\n",
        "valid_df[\"text\"] = texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcEar-hKqw6h"
      },
      "outputs": [],
      "source": [
        "nClasses = len(pd.unique(train_df['label']))\n",
        "nClasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFxcfwMAqOZ6"
      },
      "source": [
        "# NLP - Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9XAf2flqV8F"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fskl1YbGp3LX"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Define a custom dataset for our text data\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.data.iloc[index]['text']\n",
        "        label = int(self.data.iloc[index]['label'])\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzRHGP2MqUG2"
      },
      "outputs": [],
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define a collate function to prepare data for BERT model\n",
        "def collate_fn(batch):\n",
        "    texts, labels = zip(*batch)\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
        "    labels = torch.tensor(labels).to(device)\n",
        "    return inputs, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ormq8c9-qgxv"
      },
      "outputs": [],
      "source": [
        "# Create a dataloader for training set\n",
        "train_dataset = TextDataset(train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gU53CulqjVT"
      },
      "outputs": [],
      "source": [
        "# Create a dataloader for validation set\n",
        "val_dataset = TextDataset(valid_df)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoGftiCfqlh-"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained BERT model and add a classification layer\n",
        "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=nClasses)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lEQgP3QqnvX"
      },
      "outputs": [],
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JkQr_T0q_ol"
      },
      "outputs": [],
      "source": [
        "predictions_nlp = []\n",
        "# Train the model\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    for inputs, labels in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**inputs)[0]\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on validation set\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(val_loader):\n",
        "            outputs = model(**inputs)[0]\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions_nlp.append(softmax(outputs))\n",
        "            val_acc += (predicted == labels).sum().item()\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc /= len(val_loader.dataset)\n",
        "\n",
        "    print(f'Epoch {epoch+1}: Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "u49YJTHE_RKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lR3aKxik_Sgu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}